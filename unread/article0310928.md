Uncertainty is an inherent part of knowledge, and yet in an era
of contested expertise, many shy away from openly
communicating their uncertainty about what they know,
fearful of their audience’s reaction. But what effect does
communication of such epistemic uncertainty have?
Empirical research is widely scattered across many
disciplines. This interdisciplinary review structures and
summarizes current practice and research across domains,
combining a statistical and psychological perspective. This
informs a framework for uncertainty communication in
which we identify three objects of uncertainty—facts,
numbers and science—and two levels of uncertainty: direct
and indirect. An examination of current practices provides a
scale of nine expressions of direct uncertainty. We discuss
attempts to codify indirect uncertainty in terms of quality of
the underlying evidence. We review the limited literature
about the effects of communicating epistemic uncertainty on
cognition, affect, trust and decision-making. While there is
some evidence that communicating epistemic uncertainty
does not necessarily affect audiences negatively, impact can
vary between individuals and communication formats. Case
studies in economic statistics and climate change illustrate
our framework in action. We conclude with advice to guide
both communicators and future researchers in this important
but so far rather neglected field.

Communicating uncertainty about facts, numbers and science
Uncertainty: a situation in which something is not known, or something that is not known or certain (Cambridge
Dictionary) [1]
Uncertainty is all-pervasive in the world, and we regularly communicate this in everyday life. We might
say we are uncertain when we are unable to predict the future, we cannot decide what to do, there is
ambiguity about what something means, we are ignorant of what has happened or simply for a
general feeling of doubt or unease. The broad definition above from the Cambridge dictionary reflects
these myriad ways the term ‘uncertainty’ is used in normal speech.
In the scientific context, a large literature has focused on what is frequently termed ‘aleatory
uncertainty’ due to the fundamental indeterminacy or randomness in the world, often couched in
terms of luck or chance. This generally relates to future events, which we can’t know for certain. This
form of uncertainty is an essential part of the assessment, communication and management of both
quantifiable and unquantifiable future risks, and prominent examples include uncertain economic
forecasts, climate change models and actuarial survival curves.
By contrast, our focus in this paper is uncertainties about facts, numbers and science due to limited
knowledge or ignorance—so-called epistemic uncertainty. Epistemic uncertainty generally, but not
always, concerns past or present phenomena that we currently don’t know but could, at least in theory,
know or establish.1 Such epistemic uncertainty is an integral part of every stage of the scientific process:
from the assumptions we have, the observations we note, to the extrapolations and the generalizations
that we make. This means that all knowledge on which decisions and policies are based—from medical
evidence to government statistics—is shrouded with epistemic uncertainty of different types and degrees.
Risk assessment and communication about possible future events are well-established academic and
professional disciplines. Apart from the pure aleatory uncertainty of, say, roulette, the assessment of
future risks generally also contains a strong element of epistemic uncertainty, in that further
knowledge would revise our predictions: see the later example of climate change. However, there has
been comparatively little study of communicating ‘pure’ epistemic uncertainty, even though failure to
do so clearly can seriously compromise decisions (see box 1).
Recent claims that we are living in a ‘post-truth’ society [7] do not seem encouraging for scientists and policy
makers to feel able to communicate their uncertainty openly. Surveys suggest declining levels of trust in
governments and institutions [8–10], although trust in scientists apparently remains high in both the UK and
USA [11,12]. Anecdotal experience suggests a tacit assumption among many scientists and policy makers
that communicating uncertainty might have negative consequences, such as signalling incompetence,
encouraging critics and decreasing trust (e.g. [13]). By contrast, an alternative view as proposed, for example,
by the philosopher O’Neill [14] is that such transparency might build rather than undermine trust in authorities.
In order to know which of these conflicting claims hold, empirical evidence on the effects of
communicating uncertainty about facts, numbers and science needs to be collected and reviewed. This
process faces two major challenges. First, the existing empirical research on the effects of
communicating epistemic uncertainty is limited. Second, ‘communicating epistemic uncertainty’ can
mean many different things. It can be a graph of a probability distribution of the historic global
temperature change, a range around an estimate of the number of tigers in India, or a statement about
the uncertainty arising from poor-quality evidence, such as a contaminated DNA test in a criminal
court. All these variations may influence how the communication of uncertainty affects people.
In this paper, we present a cohesive framework that aims to provide clarity and structure to the issues
surrounding such communication. It combines a statistical approach to quantifying uncertainty with a
psychological perspective that stresses the importance of the effects of communication on the
audience, and is informed by both a review of empirical studies on these effects and examples of realworld uncertainty communication from a range of fields. Our aim is to provide guidance on how best
to communicate uncertainty honestly and transparently without losing trust and credibility, to the
benefit of everyone who subsequently uses the information to form an opinion or make a decision.

In contrast to the numerous attempts at generic taxonomies of uncertainty, the framework proposed in
this paper is specifically geared to the task of communication: a comparison with other proposals is made
in the next section. Based on Lasswell’s venerable model of communication [15], our framework
addresses who communicates what, in what form, to whom and to what effect while acknowledging
the relevant context as part of the characteristics of the audience. This framework for uncertainty
communication is displayed in figure 1.
The first two factors in our framework relate to who is communicating (briefly covered in §2):
— the people assessing the uncertainty, who will generally be ‘experts’ of some kind, such as individual
scientists, scientific groups such as the Intergovernmental Panel on Climate Change (IPCC), or official
bodies such as national statistical organizations. These are essentially the ‘owners’ of the uncertainty.
— the people doing the communication, who may include technical experts, communication professionals
and journalists, often acting on behalf of institutions.
Factors related to what is being communicated are (§3):
— the object about which there is uncertainty, in terms of facts, numbers or scientific models and
hypotheses
— the source of the uncertainty, as in the reasons for the lack of knowledge
— the level of the uncertainty communicated: from direct uncertainty about a fact, to the indirect
uncertainty or lack of confidence in the underlying science
— the magnitude of the uncertainty, from a small lack of precision to a substantial degree of ignorance.
Factors relating to the form of the communication (§4):
— the expression of the uncertainty, such as a full probability distribution or just a brief mention that
uncertainty exists
— the format of the uncertainty communication, in terms of numbers, visualizations or verbal statements
— the medium of the communication, such as print, online, broadcast or verbal conversation

Factors relating to whom is being communicated to (briefly covered in §5):
— the characteristics of the audiences, for example, in terms of their varying levels of numeracy and
(graphical) literacy, their expertise and knowledge of the field
— the relationship of the audience to what is being communicated, such as whether the topic is contested or
emotionally laden for them
— the relationship of the audience to the people doing the communication, including perceived credibility and
whether there is trust or distrust between audience and communicators.
Finally, factors relating to what effect the communication has on the audience (§6):
— the effect of communication on the audience’s cognition, emotion, trust, and behaviour and decision-making.
The first three sections of this paper follow the list above, briefly describing the who before concentrating
on the what and the form of the communication. We illustrate current practice in uncertainty
communication in a variety of domains including forensics, environmental health risks, public health,
conservation biology, history and military intelligence. In the last two sections, we review the current,
rather limited, academic literature evaluating the psychological effect of uncertainty communication—
including visual, verbal and numerical formats—and what is known about the moderating effects of
audience characteristics. The focus of this paper is on clarifying and structuring what is being
communicated and in what form, and reviewing what we know about its effects. Only brief comments
are provided about the who and to whom components.
Next, two case studies are presented: one in the field of climate change and one in the field of official
economic statistics. These serve to illustrate how our framework of approaching uncertainty
communication might be used to analyse current real-world graphics and messages, and inform
future research and development of more evidence-based communications. The final discussion
summarizes our contribution and provides key points for both communicators and researchers of
communication.
A worthy eventual goal would be empirically based guidance for a communicator on the likely forms,
levels and prominence of uncertainty communication that would suit their audience and aims. This
study is intended to make a start towards that aim and we summarize our conclusions (so far) for
communicators in box 5.

Other frameworks for uncertainty
Many taxonomies of uncertainty have been made in a range of disciplines, often being concerned with
‘deeper’ uncertainties inherent in any formal models that have been constructed as ways of representing
our scientific understanding of the world around us. For example, in the context of integrated assessment
models for climate change, Walker et al. [16] separated uncertainty about the context, the structure of the
model itself, the outcomes considered and the weights or values being assigned to outcomes, while van
Asselt & Rotmans [17] deconstruct ‘source’ to list five sources of uncertainty due to variability and seven
sources of uncertainty due to limited knowledge. Morgan et al. [18] emphasize numerical expression of
uncertainty, including placing probabilities on alternative models, while in contrast Kandlikar et al. [19]
proposed a qualitative scale of confidence in the underlying science, based on the degree of expert
agreement and quality of underlying evidence (this corresponds to our ‘indirect’ level of uncertainty,
as outlined in §3.3: see also the Case Study 2 on climate change before the Discussion).
Within medicine, Han [20] characterizes uncertainty in clinical decision-making in terms of
probability of future uncertain outcomes, ambiguity about what those probabilities are and
complexity of the problem. In a general scientific context, Wynne [21] considers ‘indeterminacy’ to
mean the uncertainty about what scientific knowledge fits the current situation, and ‘ignorance’ as
when we don’t know what we don’t know about the completeness and validity of our knowledge,
which by definition escapes recognition. Under the generic banner of ‘incertitude’, Stirling [22] uses
the term ambiguity for when there is doubt about outcomes, and ignorance when both probabilities
and outcomes cannot be confidently specified. Funtowicz & Ravetz’s [23] NUSAP scheme for
reporting numbers emphasizes the ‘pedigree’ (the P in NUSAP), again corresponding to our ‘indirect’
level of uncertainty, reflecting the quality of the underlying evidence.
In spite of all this activity, no consensus has emerged as to a general framework, perhaps due to the
wide variety of contexts and tasks being considered, and the complexity of many of the proposals. Our
structure, with its more restricted aim of communicating epistemic uncertainty, attempts to be a
pragmatic cross-disciplinary compromise between applicability and generality. The individual
elements of it are those factors which we believe (either through direct empirical evidence or
suggestive evidence from other fields) could affect the communication of uncertainty and thus should
be considered individually.

Who is communicating?
Following the structure given in figure 1, we note briefly the importance of identifying who is
communicating uncertainty. The people assessing and communicating uncertainty are many and
varied, from specialists assessing evidence to communication officers or the media. They might be the
same people doing both, or might be different people intimately involved—or not—in each other’s
task. Communicators may intend to have very different effects on their audiences, from strategically
deployed uncertainty (also known as ‘merchants of doubt’) to transparent informativeness. For
example, in the report on the document ‘Iraq’s Weapons of Mass Destruction: The Assessment of the
British Government’ [3] discussed in box 1 it was noted that the differences in uncertainty
communication were in part because: ‘The Government wanted a document on which it could draw
in its advocacy of its policy. The JIC sought to offer a dispassionate assessment of intelligence and
other material...’ ([4] para 327).
As will be commented on further in the to whom section, assessors and communicators of uncertainty
might have an existing relationship with the audience they are communicating to, which might be
characterized by trust or distrust. A review of the literature on source credibility falls outside the
scope of this paper, but we do want to raise the point of considering who is assessing and
communicating uncertainty, their goals for communication and their relationship with the audience.
These factors influence the choice of communication form and the effects of communication

 What is being communicated?
3.1. The object of uncertainty
Perhaps the first crucial question is: what are we uncertain about? Our specific focus is on residual
epistemic uncertainty following scientific analysis, which will generally mean constructing a model for
whatever is being studied, in the sense of a formal representation of available knowledge that contains
certain assumptions about the values of potential variables, the process by which they are observed, and
the way in which they interact.
As previously emphasized, in contrast to the existing encompassing taxonomies our more restricted
focus is on communicating epistemic uncertainty about facts, quantities and scientific hypotheses.
1. Facts: These can be formally considered as categorical variables that are (at least theoretically) directly
verifiable, for example, whether or not the midsummer arctic ice-sheet has reduced in size over the
last decade, or whether the number of homicides has increased in the last year; or one of a number
of possibilities, such as who committed a particular crime. It is important that one category might
be ‘none of the above’ (see box 2).
2. Numbers: These are continuous variables that describe the world. They may, at least in principle, be
directly observable, or they may be theoretical constructs which are used as parameters within a
model of the world. Examples of the former are the number of tigers in India, the current
proportion of unemployed, or the growth in Gross Domestic Product (GDP) in the UK last year.
Objects such as these which are being quantified always need to be carefully defined. This is clear
when the object is an artificial construct such as GDP, but the definition of ‘unemployed’ also rests
on changing convention, and even a ‘tiger’ needs unambiguous definition.
Other quantities may be parameters of scientific models that cannot be directly observed but are only
estimated within a scientific modelling framework, such as the size of risks associated with
carcinogens, the average treatment effect of a drug, or the percentage of anthropogenic influence on
global temperature over the last century—such parameters are often denoted by Greek letters such
as u.
3. Scientific hypotheses: These are theories about how the world works, expressed as structural models of
the relationship between variables, such as whether a particular exposure is carcinogenic, or the form
of the dose – response relationship between ionizing radiation and harm. We will generally be
uncertain about the most appropriate assumptions in a mathematical representation of the world.
Remembering statistician George Box’s adage that ‘all models are wrong’, but some are ‘useful’
[26, p. 792], we should in principle distinguish between the uncertainty about the adequacy of a
model to represent the world (Does my map include all existing islands?), and uncertainty about
the world itself (Does this island actually exist?). However, in practice, the lines between these often
get blurred: the Higgs Boson cannot be directly observed, and so its existence is inferred as a
component of a model that may, in future, be superseded. Scientific models and hypotheses are,
like parameters, not directly observable ‘things’, but working assumptions.
To illustrate these different objects of uncertainty, suppose you are asked to flip a coin – you flip it
and cover it up immediately without seeing it. You now need to communicate your uncertainty about
what the coin shows. In an idealized world, the answer is straightforward: your uncertainty about the
fact of whether the coin shows heads (Object 1) is expressed by your probability2 of 1
2
. This is a classic
example of communicating uncertainty through the mathematical language of probability
But the real world can be more complicated, and not so readily quantifiable. Even fair coins may not
be exactly balanced, and so there is inevitably a small element of uncertainty around the number 1
2 (Object 2).
This should be negligible provided the coin was flipped and not spun on its edge—a spun US penny coin
is reported to land heads-up only around 20% of the time [27]. But additional knowledge might alter this
probability: for example, if you know that the coin was heads-up before it was flipped, this changes the
probability that it lands heads-up to around 51%.
Further, if you suspect the person who gave you the coin was a trickster, then the coin might even be
two-headed and the probability of a head becomes one. So your confidence in the scientific model for the
coin (Object 3) is vital, and this will depend on the evidence available about the situation—something not
readily reduced to a numerical expression.3
3.2. Sources of uncertainty
A wide range of reasons for scientific uncertainty can be identified, including:
(1) variability within a sampled population or repeated measures leading to, for example, statistical
margins-of-error
(2) computational or systematic inadequacies of measurement
(3) limited knowledge and ignorance about underlying processes, and
(4) expert disagreement.
The source may affect the response to uncertainty; it is an empirically researchable question whether, for
example, difficulty in measurement versus expert disagreement as sources of uncertainty have different
effects on an audience.
Different sources of uncertainty can lead to different forms of communication. For example, when
assessing the number of migrants to a country in a preceding year, the impact of sampling variation due
to survey design may be quantifiable and therefore communicated as a confidence interval. And in
econometrics, partial identification is able to use the available (perhaps incomplete) data to communicate
bounds around statistics or parameters of interest, by considering a weaker set of assumptions than
required for point identification [2,28]. However, the uncertainty due to non-representative samples or
inaccurate responses may be more difficult to quantify than the sampling variation (and yet possibly be of
a greater magnitude) and so may need to be expressed in a different way.
 The level of uncertainty
A vital consideration in communication is what we have termed the level of uncertainty: whether the
uncertainty is directly about the object, or a form of indirect ‘meta-uncertainty’—how sure we are
about the underlying evidence upon which our assessments are based. This differs from the common
distinction made between situations where probabilities are, or are not, assumed known. In the
context of uncertainty quantification, the former is known as first-order uncertainty and the latter
second-order uncertainty, often expressed as a probability distribution over first-order probability
distributions or alternative models. An alternative categorization derives from Knight [29] and Keynes
[30], who distinguish quantifiable risks from deeper (unquantifiable) uncertainties.
In contrast to both these approaches, we have observed that the major division in practical examples
of communication comes between statements about uncertainty around the object of interest, which may
or may not comprise precise first-order probabilities, and a ‘meta-level’ reflection on the adequacy of
evidence upon which to make any judgement whatever. We therefore consider that, when
communicating, it is most appropriate to distinguish two fundamental levels of uncertainty:
Direct uncertainty about the fact, number or scientific hypothesis. This can be communicated either in
absolute quantitative terms, say a probability distribution or confidence interval, or expressed
relative to alternatives, such as likelihood ratios, or given an approximate quantitative form, verbal
summary and so on.
Indirect uncertainty in terms of the quality of the underlying knowledge that forms a basis for any claims
about the fact, number or hypothesis. This will generally be communicated as a list of caveats about
the underlying sources of evidence, possibly amalgamated into a qualitative or ordered categorical scale.
This division neither matches the traditional split into first/second-order nor quantified/unquantified
uncertainty. Direct uncertainty may be assessed through modelling or through expert judgement,
involving aspects of both first- and second-order uncertainty, and may be quantified to a greater or
lesser extent, whereas indirect uncertainty is a reflexive summary of our confidence in the models or
the experts.4 An example of a system designed to communicate indirect uncertainty is the GRADE
system of summarizing overall quality of evidence, which we discuss further in §4.
Box 3 demonstrates the difference between direct and indirect uncertainty within a legal context
where we hope the distinction between the two levels is particularly clear.
3.4. The magnitude of the uncertainty
It seems intuitive that the magnitude of uncertainty being communicated would likely influence the
audience’s response to it—it could indeed be seen as one of the commonest goals of uncertainty
communication. However, it is often not explicitly drawn out as an important variable in empirical work
(see §6 where this is discussed).
4. In what form is the uncertainty communicated?
4.1. Expressions of uncertainty
Each of the different kinds of uncertainty discussed in §3 can be expressed in a wide range of forms, and
these forms may affect the effects of uncertainty communication. In this section, we consider the space
created by the different dimensions that we have used to define uncertainty and how it can be filled
by different expressions.
4.1.1. Direct uncertainty (absolute expressions)
Direct uncertainty about a fact, number or scientific hypothesis is the type of uncertainty which can be the most
precisely expressed and therefore lends itself to thewidest possible range of forms of expression. In figure 2, we
list these forms, in order of their decreasing precision (capability of expressing detail of magnitude).
Expressions at the top of the list can be considered as Donald Rumsfeld’s ‘known unknowns’ [24],
whereas his ‘unknown unknowns’ would fall under expression vii, in which uncertainty is
acknowledged without being able to provide a list of possibilities.
In order to explore whether each in this list of nine expressions of absolute, direct uncertainty could
be applied to all three objects of uncertainty in our framework - categorical or binary facts, continuous
variables (numbers) and models - we set out to find real examples of each in use. The results of our
search are shown in table 1. We were not able to find examples for each cell in the table, illustrating
where some usages are rare at best. However, our intention was both to test the comprehensiveness of
our framework and to illustrate it to help others identify how it can be applied. We fully admit that
some of the entries are ambiguous: for example, as we shall see in box 4, the IARC’s claim of a
‘probable carcinogen’ is more an indirect summary of the quality of evidence for carcinogenicity,
rather than a direct expression of probability and so may not belong in the table at all.
Direct uncertainty (relative expressions)
Relative uncertainty about competing hypotheses or values for a measure can also be expressed in different
forms. Verbal comparisons include statements of the form ‘A is more likely than B’, while numerical
expressions include likelihood ratios for comparing facts and scientific hypotheses, likelihood functions
for relative support for different numbers, and comparative measures of model adequacy such as the
Akaike Information Criterion [61] or Bayesian Information Criterion [62]: formal definitions are provided
in the Technical appendix on statistical approaches to communicating epistemic uncertainty. P-values are
a measure of conflict between data and a hypothesis, and are certainly not direct expressions of a
probability of hypotheses. However, as described in the Technical appendix, in many circumstances they
correspond to a specific confidence interval for a numerical parameter.
4.1.3. Indirect uncertainty (quality of underlying evidence)
Methods for communicating the quality of the underlying evidence do not give quantitative information
about absolute values or facts, but summarize the subjective confidence we have in any claim.
In order to attempt to assess indirect uncertainty, a number of fields have established checklists to try
to assess the quality of evidence in as objective a way as possible. These may relate to either an individual
claim, such as the CONSORT system, for determining the characteristics of the claims resulting from a
randomized controlled trial [63], and the Maryland Scale of Scientific Methods, for determining the
strength of a crime prevention study [64], or the totality of evidence, attempting to take into account the
quality, quantity and consistency of multiple studies to give an overall assessment of the confidence
we can have in a particular assertion; see [65,66] for reviews. These tools provide the basis for systems
that attempt to communicate overall quality of evidence (although the distinction between methods of
assessment and methods of communication of indirect uncertainty is rarely made).
Many methods of communicating indirect uncertainty have been developed in different fields.
Limitations in the underlying evidence might be summarized by qualitative verbal caveats, or an ordered
set of categories (which may be communicated numerically, graphically or verbally). For example, the
GRADE Working Group has established a scale for communicating the quality of the evidence
underlying claims about the effects of medical interventions, which ranges from ‘Very low quality’,
graphically represented as a single plus symbol and/or circle, to ‘High Quality’, graphically represented
as 4 plus symbols and/or circles [67]. Other examples are the ‘padlock’ ratings used by the UK’s
Educational Endowment Foundation [68] (figure 3), or the US National Intelligence Council’s
recommendation that intelligence analysts provide a qualitative assessment of analytic confidence on a
high/medium/low scale ‘based on the scope and quality of information supporting our judgments’ (p. 5
[69]). In effect, such ordered scales provide a form of ‘star-rating’ for the conclusions.
These broad categorical ratings are used when the impact of poorer quality evidence is difficult to
quantify. One issue with such broad categorical ratings or verbal descriptions (e.g. ‘high quality’) is
that their meaning is in part dependent on the context of their use: at what threshold evidence is
classified as high quality or low quality might depend on the research field or topic. The audience,
especially if they are non-experts, might not be aware of this. In addition, research has shown that
there is considerable variation in people’s interpretation of verbal probability and uncertainty words
such as ‘likely’ [70– 73]. There might be a similar variability in what people interpret ‘high quality’ or
‘low quality’ to mean, which might make such broad categorical ratings or verbal descriptions less
effective. However, it might be hoped that, with additional knowledge or judgement, some caveats
could contribute to a direct, quantitative expression of uncertainty: for example, by widening a
confidence interval due to the potential systematic bias in a survey.
In practice, both direct and indirect uncertainties are often expressed simultaneously, as
demonstrated by the following Cochrane systematic review:
‘We found that giving immunotherapy, mainly vaccine-based (aiming to activate the host immune system to
induce human immune response to tumour-specific antigens), after surgery or radiotherapy did not, on
average, make people live longer’. ‘We found a small, but not statistically significant, improvement in OS (HR
0.94, 95% CI 0.83 to 1.06; P ¼ 0.35), ... ; high-quality evidence)’ [74]
In this example, the number of primary interest is the hazard ratio (HR)—the proportional change in
overall survival (OS) for people given immunotherapy. The HR is estimated to be 0.94, corresponding to a
6% reduction in the risk of dying in a fixed time period, and the direct, absolute uncertainty around this
figure is communicated as a 95% confidence interval (0.83–1.06). This is a ‘ii’ on our scale of methods of
expressions for communicating direct, absolute uncertainty—a summary of a distribution for the true value.
The p-value (0.35) expresses the weak evidence that the true value of the HR is different from 1 (i.e.
that those given immunotherapy really did live longer than those who were not given this therapy).
Formally, this says there is a 35% chance of having observed at least the 6% relative change in
survival if there were actually no effect of the immunotherapy (and all the other modelling
assumptions are correct)—an effect not considered to be statistically significant (when the alpha level
is set at the conventional 0.05). This p-value can be translated to an absolute expression: it means that
a 65% confidence interval for the true effect just excludes 1.
The quality of the evidence behind these direct claims is expressed through the GRADE scale, with
‘high-quality’ and the symbolic 4 ‘þ’ (figure 4) meaning that we as readers can put good faith in both the
confidence interval and the p-value.
This amount of information could potentially be overwhelming, and difficult to illustrate graphically
and interpret, so organizations have (apparently without recourse to empirical testing) sought less
comprehensive forms of uncertainty communication. These may try to conflate the different levels of
uncertainty to try to simplify the message, but box 4 shows this has clear potential for confusion.
We cite these examples as a useful warning to practitioners considering constructing a ‘simplified’
method of communicating the uncertainties in their field.
Methods have been proposed for turning indirect into direct uncertainty. In the context of a metaanalysis of healthcare interventions, Turner et al. [75] demonstrate that experts can take caveats about
lower-quality studies and express their impact in terms of subjective probability distributions of
potential biases. When these are added to the nominal confidence intervals, the intervals
appropriately widen and the heterogeneity of the studies are explained. These techniques have been
tried in a variety of applications [76,77] and show promise, although they do require acceptance of
quantified expert judgement.
4.2. Format and medium of uncertainty communication
The other important aspects of the ‘how’ in our framework of uncertainty communication (figure 1) are
the format and the medium. Uncertainty can be expressed in one (or a combination) of three different
formats: visual, numerical and/or verbal. The appropriate format in part depends on the medium of
communication, which might be written and printed official reports, online websites, smart phone
applications, print media, television, or spoken in person or on the radio. We therefore consider these
two aspects of format and medium together. However, these different formats have the potential to
carry different levels of information and therefore choosing one is not simply a design choice—it can
influence the type of expression of uncertainty available and its potential effect on the audience.
Expressions i –iv in §4.1 are predominantly numerical or visual expressions; expressions v-ix are
predominantly verbal (and less precise).
Whereas numerical (numbers) and verbal (words) communication are relatively constrained in their
design, there are a variety of ways to communicate uncertainty visually. Examples of common ways to
visualize epistemic uncertainty around a number, expressed as an estimate with a range (‘i’ or ‘ii’ in our
scale), are presented in figure 5. Error bars are widely used in scientific and other publications to illustrate
the bounds of a confidence interval, but provide no indication of the underlying distribution of the
number. Other visualizations attempt to give an (approximate) idea of this underlying distribution:
for example, diamonds, which are often used when considering treatment effects in a medical metaanalysis, or violin plots, which are designed to give a more accurate idea of the underlying
distribution. Fan plots are designed to show the bounds of several different confidence intervals (often
coloured to emphasize the changing probability density going further from the point) and are used,
for example, by the Bank of England when communicating past and forecasted future GDP estimates.
Finally, density strips are the most accurate representation of the underlying probability distribution
around the point estimate.
Such visualizations have primarily been explored within the context of future risks, and Spiegelhalter
et al. [78] reviewed different types of visualizations of uncertainty about the future, such as bar charts,
icon arrays, fan charts or probability distributions. By contrast, MacEachren et al. [79] reviewed
different types of visualization of epistemic uncertainty in spatial data such as maps or medical
imaging: various attributes of the colours and lines used to construct a map may be varied to
illustrate uncertainty [79], while colour saturation, crispness and opacity, as well as the addition of
specific indicators (glyphs) may give uncertainty information (such as the IPCC’s use of the ‘þ’ sign
on its climate maps). One main conclusion from both reviews is that whereas a wide variety of types
of graphics have been developed to communicate probabilities, there is limited empirical evidence of
how alternative formats may influence audience understanding and response.
